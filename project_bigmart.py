# -*- coding: utf-8 -*-
"""project_bigmart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sx_FQqdNiazstOFBNxVDxlTN2_cjxFDq
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
import warnings
warnings.filterwarnings('ignore')

data=pd.read_csv('/content/bigmart_sales_data.csv')
data.head()

data.isnull().sum()
data['Item_Weight'].fillna(data['Item_Weight'].mean(),inplace=True)
data['Outlet_Size'].fillna(data['Outlet_Size'].mode()[0],inplace=True)
le = LabelEncoder()
data['Item_Fat_Content'] = le.fit_transform(data['Item_Fat_Content'])
data['Outlet_Location_Type'] = le.fit_transform(data['Outlet_Location_Type'])
data['Outlet_Type'] = le.fit_transform(data['Outlet_Type'])
data['Outlet_Size'] = le.fit_transform(data['Outlet_Size'])
data['item_Type'] = le.fit_transform(data['Item_Type'])

data['Item_Visibility']=data['Item_Visibility'].replace(0,data['Item_Visibility'].mean())
data['item_Type_Combined']=data['Item_Identifier'].apply(lambda x:x[0:2])
data['item_Type_Combined']=data['item_Type_Combined'].map({'FD':'Food','NC':'Non-Consumable','DR':'Drinks'})
data['item_Type_Combined']=le.fit_transform(data['item_Type_Combined'])
data.drop(['Item_Identifier','Outlet_Identifier'], axis=1,inplace=True)

X=data.drop('Item_Outlet_Sales',axis=1)
y=data['Item_Outlet_Sales']

for col in X.select_dtypes(include=['object']):
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col])
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
model=LinearRegression()
model.fit(X_train,y_train)
y_pred=model.predict(X_test)
mse=mean_squared_error(y_test,y_pred)
print('Mean Squared Error:',mse)
plt.scatter(y_test,y_pred,alpha=0.5)
plt.xlabel('Actual scale')
plt.ylabel('predicted scale')
plt.title('actual vs predicted scales')
plt.show()

